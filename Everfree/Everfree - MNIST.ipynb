{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as f\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numEpochs = 100\n",
    "lr =  1e-3\n",
    "use_gpu = torch.cuda.is_available()\n",
    "use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MNIST(\"../data/MNIST\", transform=imgTransform, train=False, download=True)\n",
    "train = MNIST(\"../data/MNIST\", transform=imgTransform, train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = DataLoader(train, batch_size=128, shuffle=True)\n",
    "testData = DataLoader(test, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder, used for feature extraction\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureExtractor = autoencoder().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(featureExtractor.parameters(), lr=lr,\n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [0/100], loss:0.0549\n",
      "epoch [1/100], loss:0.0463\n",
      "epoch [2/100], loss:0.0407\n",
      "epoch [3/100], loss:0.0416\n",
      "epoch [4/100], loss:0.0372\n",
      "epoch [5/100], loss:0.0363\n",
      "epoch [6/100], loss:0.0345\n",
      "epoch [7/100], loss:0.0341\n",
      "epoch [8/100], loss:0.0325\n",
      "epoch [9/100], loss:0.0311\n",
      "epoch [10/100], loss:0.0307\n",
      "epoch [11/100], loss:0.0294\n",
      "epoch [12/100], loss:0.0293\n",
      "epoch [13/100], loss:0.0307\n",
      "epoch [14/100], loss:0.0284\n",
      "epoch [15/100], loss:0.0276\n",
      "epoch [16/100], loss:0.0271\n",
      "epoch [17/100], loss:0.0274\n",
      "epoch [18/100], loss:0.0275\n",
      "epoch [19/100], loss:0.0270\n",
      "epoch [20/100], loss:0.0262\n",
      "epoch [21/100], loss:0.0267\n",
      "epoch [22/100], loss:0.0289\n",
      "epoch [23/100], loss:0.0253\n",
      "epoch [24/100], loss:0.0253\n",
      "epoch [25/100], loss:0.0250\n",
      "epoch [26/100], loss:0.0253\n",
      "epoch [27/100], loss:0.0270\n",
      "epoch [28/100], loss:0.0271\n",
      "epoch [29/100], loss:0.0277\n",
      "epoch [30/100], loss:0.0267\n",
      "epoch [31/100], loss:0.0273\n",
      "epoch [32/100], loss:0.0286\n",
      "epoch [33/100], loss:0.0279\n",
      "epoch [34/100], loss:0.0271\n",
      "epoch [35/100], loss:0.0262\n",
      "epoch [36/100], loss:0.0263\n",
      "epoch [37/100], loss:0.0266\n",
      "epoch [38/100], loss:0.0255\n",
      "epoch [39/100], loss:0.0240\n",
      "epoch [40/100], loss:0.0263\n",
      "epoch [41/100], loss:0.0266\n",
      "epoch [42/100], loss:0.0258\n",
      "epoch [43/100], loss:0.0271\n",
      "epoch [44/100], loss:0.0267\n",
      "epoch [45/100], loss:0.0248\n",
      "epoch [46/100], loss:0.0255\n",
      "epoch [47/100], loss:0.0254\n",
      "epoch [48/100], loss:0.0247\n",
      "epoch [49/100], loss:0.0250\n",
      "epoch [50/100], loss:0.0276\n",
      "epoch [51/100], loss:0.0241\n",
      "epoch [52/100], loss:0.0247\n",
      "epoch [53/100], loss:0.0249\n",
      "epoch [54/100], loss:0.0244\n",
      "epoch [55/100], loss:0.0265\n",
      "epoch [56/100], loss:0.0236\n",
      "epoch [57/100], loss:0.0254\n",
      "epoch [58/100], loss:0.0248\n",
      "epoch [59/100], loss:0.0260\n",
      "epoch [60/100], loss:0.0259\n",
      "epoch [61/100], loss:0.0270\n",
      "epoch [62/100], loss:0.0247\n",
      "epoch [63/100], loss:0.0268\n",
      "epoch [64/100], loss:0.0246\n",
      "epoch [65/100], loss:0.0258\n",
      "epoch [66/100], loss:0.0265\n",
      "epoch [67/100], loss:0.0277\n",
      "epoch [68/100], loss:0.0236\n",
      "epoch [69/100], loss:0.0249\n",
      "epoch [70/100], loss:0.0238\n",
      "epoch [71/100], loss:0.0251\n",
      "epoch [72/100], loss:0.0250\n",
      "epoch [73/100], loss:0.0252\n",
      "epoch [74/100], loss:0.0259\n",
      "epoch [75/100], loss:0.0243\n",
      "epoch [76/100], loss:0.0237\n",
      "epoch [77/100], loss:0.0265\n",
      "epoch [78/100], loss:0.0264\n",
      "epoch [79/100], loss:0.0242\n",
      "epoch [80/100], loss:0.0232\n",
      "epoch [81/100], loss:0.0247\n",
      "epoch [82/100], loss:0.0246\n",
      "epoch [83/100], loss:0.0247\n",
      "epoch [84/100], loss:0.0249\n",
      "epoch [85/100], loss:0.0254\n",
      "epoch [86/100], loss:0.0251\n",
      "epoch [87/100], loss:0.0263\n",
      "epoch [88/100], loss:0.0233\n",
      "epoch [89/100], loss:0.0250\n",
      "epoch [90/100], loss:0.0255\n",
      "epoch [91/100], loss:0.0240\n",
      "epoch [92/100], loss:0.0243\n",
      "epoch [93/100], loss:0.0242\n",
      "epoch [94/100], loss:0.0256\n",
      "epoch [95/100], loss:0.0236\n",
      "epoch [96/100], loss:0.0246\n",
      "epoch [97/100], loss:0.0254\n",
      "epoch [98/100], loss:0.0259\n",
      "epoch [99/100], loss:0.0236\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(numEpochs):\n",
    "    for data in trainData:\n",
    "        img, _ = data\n",
    "        img = Variable(img).cuda()\n",
    "\n",
    "        output = featureExtractor(img)\n",
    "        loss = criterion(output, img)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch, numEpochs, loss.data.item()))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, './dc_img/image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021843060851097107\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "for data in testData:\n",
    "    img, _ = data\n",
    "    img = Variable(img).cuda()\n",
    "\n",
    "    output = featureExtractor(img)\n",
    "    loss = criterion(output, img)\n",
    "    \n",
    "print(loss.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 8, 2, 2])\n",
      "torch.Size([60000, 32])\n"
     ]
    }
   ],
   "source": [
    "trainFeat = torch.empty(0,device='cuda:0',)\n",
    "for data in trainData:\n",
    "        img, _ = data\n",
    "        img = Variable(img).cuda()\n",
    "\n",
    "        output = featureExtractor.encode(img)\n",
    "        trainFeat = torch.cat((trainFeat, output), 0)\n",
    "        \n",
    "print(trainFeat.shape)\n",
    "trainFeat = testFeat.view(60000,32)\n",
    "print(trainFeat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 8, 2, 2])\n",
      "torch.Size([10000, 32])\n"
     ]
    }
   ],
   "source": [
    "testFeat = torch.empty(0,device='cuda:0',)\n",
    "for data in testData:\n",
    "        img, _ = data\n",
    "        img = Variable(img).cuda()\n",
    "\n",
    "        output = featureExtractor.encode(img)\n",
    "        testFeat = torch.cat((testFeat, output), 0)\n",
    "print(testFeat.shape)\n",
    "testFeat = testFeat.view(10000,32)\n",
    "print(testFeat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'ToTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-291fd53b1347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'ToTensor'"
     ]
    }
   ],
   "source": [
    "torch.tensor.ToTenso r(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root node in our Everfree Tree, only direction\n",
    "class root(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.layer1 = nn.sequential(\n",
    "            nn.Linear(32, 8),\n",
    "            nn.ReLU(True))\n",
    "        self.layer2 = nn.sequential(\n",
    "            nn.Linear(8, 1),\n",
    "            nn.sigmoid())\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaf node, has two possible outputs, direction and error\n",
    "class leaf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.layer1 = nn.sequential(\n",
    "            nn.Linear(32, 8),\n",
    "            nn.ReLU(True))\n",
    "        self.layer2 = nn.sequential(\n",
    "            nn.Linear(8, 2),\n",
    "            nn.sigmoid())\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
